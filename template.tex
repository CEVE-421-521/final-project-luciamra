% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{article}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Final Project Report},
  pdfauthor={Your Name (NetID)},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Final Project Report}
\author{Your Name (NetID)}
\date{Tue., Apr.~30}

\begin{document}
\maketitle

\section{Introductions}\label{introductions}

\subsection{Problem Statement}\label{problem-statement}

The goal of this project is to improve our flood induced house-elevation
policy search model by tackling the effects of uncertainty in sea-level
rise. It is important to be able to assess the vulnerability of coastal
communities with respect to flooding so that we can develop solutions
that improve people's quality of living and protection. Flooding is a
primary hazard coastal communities have to face, as they are
particularly exposed due to development within and the expansion of
floodplains. Flooding is becoming more common, even in the absence of
extreme weather events. This is detrimental to communities because
consistent flooding can clog storm drains, flood streets, inundate and
fatigue coastal infrastructure and ecosystems, and affect freshwater
supplies. One of the strongest drivers of this increase in frequency and
intensity of flooding is human induced climate change. Climate change is
having a significant effect on many of the factors that contribute to
flooding, specifically within sea-level rise, and this flooding is
having detrimental impacts on coastal communities. Even locally, more
than a third of Harris county falls within a FEMA-designated floodplain,
and according to experts, what is now considered a 500-year floodplain
(a 1 in 500 chance of flooding each year) will soon be considered a
100-year floodplain due to the increase in the rate and intensity of
flooding. The intensity of climate hazards such as flooding will only
increase in the absence of measures to reduce emissions. If this is the
case, we must reduce the risk and vulnerability of exposed communities
if we want to decrease the damage and destruction of coastal flood
impacts. The decision-support tool we are building provides insight into
risk management strategies that can be taken in order to reduce risk,
where risk is characterized by damage costs. This mitigation strategy is
the elevation of a home or building in a flood-prone area, which
essentially decreases the effect of flooding on the building and as a
result, the damages and resulting damage costs.

\subsection{Selected Feature}\label{selected-feature}

As the climate warms and humans continue to emit greenhouse gasses into
the atmosphere, the sea-level will continue to rise at alarming rates.
According to the European Environment Agency, the global sea level has
already risen about 21 cm since 1900 and the rate at which it is rising
is accelerating. This is largely due to the decrease in freshwater
impoundment in the face of a significant increase in ice sheet melt and
thermal expansion. Sea-level rise is a major contributor to coastal
flooding around the world, and it is one of the elements factored into
our policy search model.\\
In our analysis we must make a lot of assumptions in order to quantify
the risk associated with flooding in the area of our home. This
estimation of risk is particularly apparent in the definition of the
states of the world (SOWs), or scenarios, over which we inspect our
damages and costs. The components of our SOWs are sea-level rise, storm
surge, and the discount rate, all of which are estimated to a certain
degree due to uncertainty in climate change, future economies, and
physical dynamics among other things. These estimations can lead to
overconfidence in results that are not fully representative of real
world happenings, so while it is impossible to perfectly model each
component, we can implement more in depth analysis of the individual
factors contributing to flooding. To stress the importance of the
representation of the SOW components, if we underestimate the frequency
or intensity of flooding, we will then underestimate the amount of
damages induced, and then the cost of the damages, so in the end, the
analysis of these components is the first step in quantifying risk. In
this project I will focus on the improvement of the modeling of one of
the scenario components, sea-level rise. The current model is
probabilistic and the parameters used to model sea-level rise are
estimated and quantified without having their uncertainty accounted for.
This is difficult because sea-level rise can be considered a ``deep''
uncertainty, meaning experts cannot agree on the probability
distributions associated with the contributing variables. The estimation
of deeply uncertain values as is done in the model can lead to skewed
results. Instead, in this project sea-level rise will be considered
using rejection sampling to produce a sample of parameters that are
consistent with expert predictions of future sea-level rise, and better
account for the uncertainty and the probabilities associated with the
contributing parameters.

\section{Literature Review}\label{literature-review}

Provide a brief overview of the theoretical background related to your
chosen feature. Cite at least two relevant journal articles to support
your approach (see
\href{https://quarto.org/docs/authoring/footnotes-and-citations.html}{Quarto
docs} for help with citations). Explain how these articles contribute to
the justification of your selected feature.

As previously mentioned, our house elevation decision-support tool is a
probabilistic model of flooding and the resulting damages. The main
factor that distinguishes this model from a robust decision making model
is that it provides a single optimal solution with some quantity that
serves as a ranking or comparison to the other possible solutions. This
solution though, must be taken with a grain of salt because the downfall
of probabilistic models is that they fail to truly consider uncertainty.
Sriver et al.~discuss the difference between a probabilistic model and a
robust decision making model in their paper with respect to sea-level
rise and the parameters with ranging uncertainties that contribute to
this measurement. The probabilistic analysis, like the one we are
modeling, uses the best available information to create one single joint
distribution for all uncertain parameters. This means that it uses
probability density functions for all of the input parameters instead of
distinguishing between well characterizable and deep uncertainty values.
This allows the model to search for an optimal strategy for the
best-estimate distribution. Again, the downside is that these models do
not fully characterize uncertainty, which is why robust decision making
models are beneficial. These models almost work backwards, beginning
with a policy under consideration and identifying the SOWs where the
policy performs best. It uses a single probability density function to
represent well-characterized uncertainties, and then the model is run
over an experimental design that is informed by the deeply uncertain
factors. The resulting database of model runs can be used to identify
the conditions where the decision fails to meet some established
criteria, and it will provide more information about things that have
limited available information. Interestingly, robust decision making
models make no statements about the likelihood of the scenarios and is
additionally beneficial because it establishes a regular relationship
between analyst and policymaker. To understand the effects of using a
probabilistic or robust decision making model to represent sea-level
rise, we must consider the types of uncertainty that influence this
metric. As previously stated, sea-level rise is considered a ``deep''
uncertainty, and to zoom in on why, we must examine the drivers. There
are three main sources of uncertainty when modeling sea-level rise.
First, the projections depend on scenarios of external factors, such as
global warming and emissions, and they often dominate outcomes. We want
to be careful about what emission scenarios we choose because the ones
used don't always represent absolute bounds and that can lead to
overconfidence in our results. The second source is parameter
uncertainty and internal variability, which consists of thermal
expansion, melting land ice, and changes in ocean topography. The third
source is model structure uncertainty, which is common because of the
variety in the types of models and their inability to truly represent
the real world. In our analysis we will be using the following Lempert
quadratic sea level rise equation: {[}SLR = a + b t + c t\^{}2 +
c\^{}\{\emph{\} I (t - t\^{}\{}\}){]} I will expand on how this equation
will be implemented in the ``Methodology'' section of this report, but
in order to understand the uncertainties that contribute to sea-level
rise we must see what parameters we are using in the calculation. The
Sriver et al.~paper nicely combines the different types of parameters
and their respective uncertainties into a table as shown below. Some of
the parameters are not to be considered for our analysis, but the
parameters shown are the ones that contribute to sea-level rise. There
two sources that contribute to how we characterize uncertainty are how
much evidence there is for something and how much people agree on it.
There is sufficient understood information about parameters a, b, and c,
so they are considered well-characterized and can be comfortably
represented using a joint probability distribution. On the other hand,
there is little direct observational evidence for potential changes in
system dynamics but there is some agreement on the upper bounds of how
it will contribute to sea level rise in the next century, so the changes
in system dynamics, characterized as c* and t*, are classified as
``deep'' uncertainties. The results in the papers on sea-level rise were
enough to prove that sea-level is a significant factor in flood risk and
that the acknowledgement of uncertainty can play a key role in results.
According to Oddo et al.~even small sea-level changes can increase flood
risk by orders of magnitude. They found that while Van Dantizig's linear
sea-level rise model predicted sea-level rise in the year 2100 to be
\textasciitilde0.7m, the beta-calibrated forecasts predicted it to be at
\textasciitilde1.2m. This is a significant outcome because it puts Van
Dantzig's result below 85\% of beta-calibrated forecasts. This goes to
show that the inclusion of proper uncertainty characterization in
sea-level rise drastically affects the bounds to be analyzed. Applying
these new values to the model increases variability in expected model
damages and the expected optimal total cost index by 11\%, demonstrating
that the model output was significantly sensitive to changes in
sea-level.

\section{Methodology}\label{methodology}

\subsection{Implementation}\label{implementation}

You should make your modifications in either the \texttt{HouseElevation}
or \texttt{ParkingGarage} module. Detail the steps taken to implement
the selected feature and integrate it into the decision-support tool.
Include code snippets and explanations where necessary to clarify the
implementation process.

\subsection{Validation}\label{validation}

As we have seen in labs, mistakes are inevitable and can lead to
misleading results. To minimize the risk of errors making their way into
final results, it is essential to validate the implemented feature.
Describe the validation techniques used to ensure the accuracy and
reliability of your implemented feature. Discuss any challenges faced
during the validation process and how they were addressed.

\section{Results}\label{results}

Present the results obtained from the enhanced decision-support tool.
Use tables, figures, and visualizations to clearly communicate the
outcomes. Provide sufficient detail to demonstrate how the implemented
feature addresses the problem statement. Use the
\texttt{\#\textbar{}\ output:\ false} and/or
\texttt{\#\textbar{}\ echo:\ false} tags to hide code output and code
cells in the final report except where showing the output (e.g.g, a
plot) or the code (e.g., how you are sampling SOWs) adds value to the
discussion. You may have multiple subsections of results, which you can
create using \texttt{\#\#}.

\section{Conclusions}\label{conclusions}

\subsection{Discussion}\label{discussion}

Analyze the implications of your results for climate risk management.
Consider the context of the class themes and discuss how your findings
contribute to the understanding of climate risk assessment. Identify any
limitations of your approach and suggest potential improvements for
future work.

\subsection{Conclusions}\label{conclusions-1}

Summarize the key findings of your project and reiterate the
significance of your implemented feature in addressing the problem
statement. Discuss the broader implications of your work for climate
risk management and the potential for further research in this area.

\section{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{0}{1}
\end{CSLReferences}



\end{document}
